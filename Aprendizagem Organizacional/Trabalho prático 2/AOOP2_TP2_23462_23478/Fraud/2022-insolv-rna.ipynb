{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T21:49:37.543270Z",
     "iopub.status.busy": "2022-05-30T21:49:37.542384Z",
     "iopub.status.idle": "2022-05-30T21:49:37.621743Z",
     "shell.execute_reply": "2022-05-30T21:49:37.620837Z",
     "shell.execute_reply.started": "2022-05-30T21:49:37.543230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       ip_address  email_address  billing_postal billing_address\n",
       "0            112              0           34491           12351\n",
       "1            192              0           34555             691\n",
       "2            185              0           33611           28583\n",
       "3             68              0           33520             019\n",
       "4            117              2           33889            1023\n",
       "...          ...            ...             ...             ...\n",
       "19995          4              0           33001            5677\n",
       "19996         83              2           33470           38370\n",
       "19997        211              1           33552             442\n",
       "19998         18              1           34414            6355\n",
       "19999        211              2           32240            8867\n",
       "\n",
       "[20000 rows x 4 columns]>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    " \n",
    "\n",
    "#Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Importar o Dataset\n",
    "df = pd.read_csv('../Fraud/dataset/registration_data_20K_full.csv',sep=',',header=0)\n",
    "i = 0\n",
    "for d in df['ip_address']:\n",
    "    d = (d.split(\".\",1))\n",
    "    #print(d[0])\n",
    "    df.loc[i, 'ip_address'] = d[0]\n",
    "    i = i+1\n",
    "j=0\n",
    "for d in df['email_address']:\n",
    "    d = (d.split(\"@\",1))\n",
    "    #print(d[1])\n",
    "    if(d[1] == \"example.net\"):\n",
    "        df.loc[j, 'email_address'] = 0\n",
    "    elif(d[1] == \"example.org\"):\n",
    "        df.loc[j, 'email_address'] = 1\n",
    "    elif(d[1] == \"example.com\"):\n",
    "        df.loc[j, 'email_address'] = 2\n",
    "    j = j + 1\n",
    "z=0\n",
    "for d in df['billing_address']:\n",
    "    d = (d.split(\" \",1))\n",
    "    #print(d[0])\n",
    "    df.loc[z, 'billing_address'] = d[0]\n",
    "    z = z + 1\n",
    "df = df.drop('billing_state', axis=1)\n",
    "df = df.drop('user_agent', axis=1)\n",
    "df = df.drop('phone_number', axis=1)\n",
    "df = df.drop('EVENT_TIMESTAMP', axis=1)\n",
    "df[\"EVENT_LABEL\"]= df[\"EVENT_LABEL\"].map({\"legit\": 1,\"fraud\": 0})\n",
    "dataset = df.fillna(0).copy()\n",
    "X = dataset.drop('EVENT_LABEL', axis=1)   #Colunas usadas para calcular a Insolvencia. ContÃªm as features\n",
    "y= dataset.EVENT_LABEL                  #Parametro a ser calculado\n",
    "X.head\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T21:51:17.316903Z",
     "iopub.status.busy": "2022-05-30T21:51:17.316448Z",
     "iopub.status.idle": "2022-05-30T21:52:05.629120Z",
     "shell.execute_reply": "2022-05-30T21:52:05.628253Z",
     "shell.execute_reply.started": "2022-05-30T21:51:17.316869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paulo Garrido\\AppData\\Local\\Temp\\ipykernel_26688\\3624732158.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train=np.asarray(X_train).astype(np.int)\n",
      "C:\\Users\\Paulo Garrido\\AppData\\Local\\Temp\\ipykernel_26688\\3624732158.py:11: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_train=np.asarray(y_train).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1400 [==============================] - 1s 678us/step - loss: 32.1414 - accuracy: 0.9301\n",
      "Epoch 2/150\n",
      "1400/1400 [==============================] - 1s 678us/step - loss: 0.2718 - accuracy: 0.9492\n",
      "Epoch 3/150\n",
      "1400/1400 [==============================] - 1s 726us/step - loss: 0.2174 - accuracy: 0.9492\n",
      "Epoch 4/150\n",
      "1400/1400 [==============================] - 1s 667us/step - loss: 0.2040 - accuracy: 0.9492\n",
      "Epoch 5/150\n",
      "1400/1400 [==============================] - 1s 663us/step - loss: 0.2013 - accuracy: 0.9492\n",
      "Epoch 6/150\n",
      "1400/1400 [==============================] - 1s 675us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 7/150\n",
      "1400/1400 [==============================] - 1s 687us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 8/150\n",
      "1400/1400 [==============================] - 1s 672us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 9/150\n",
      "1400/1400 [==============================] - 1s 669us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 10/150\n",
      "1400/1400 [==============================] - 1s 662us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 11/150\n",
      "1400/1400 [==============================] - 1s 667us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 12/150\n",
      "1400/1400 [==============================] - 1s 705us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 13/150\n",
      "1400/1400 [==============================] - 1s 702us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 14/150\n",
      "1400/1400 [==============================] - 1s 712us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 15/150\n",
      "1400/1400 [==============================] - 1s 688us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 16/150\n",
      "1400/1400 [==============================] - 1s 677us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 17/150\n",
      "1400/1400 [==============================] - 1s 717us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 18/150\n",
      "1400/1400 [==============================] - 1s 675us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 19/150\n",
      "1400/1400 [==============================] - 1s 779us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 20/150\n",
      "1400/1400 [==============================] - 1s 663us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 21/150\n",
      "1400/1400 [==============================] - 1s 675us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 22/150\n",
      "1400/1400 [==============================] - 1s 671us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 23/150\n",
      "1400/1400 [==============================] - 1s 673us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 24/150\n",
      "1400/1400 [==============================] - 1s 675us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 25/150\n",
      "1400/1400 [==============================] - 1s 687us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 26/150\n",
      "1400/1400 [==============================] - 1s 682us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 27/150\n",
      "1400/1400 [==============================] - 1s 676us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 28/150\n",
      "1400/1400 [==============================] - 1s 667us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 29/150\n",
      "1400/1400 [==============================] - 1s 677us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 30/150\n",
      "1400/1400 [==============================] - 1s 722us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 31/150\n",
      "1400/1400 [==============================] - 1s 653us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 32/150\n",
      "1400/1400 [==============================] - 1s 674us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 33/150\n",
      "1400/1400 [==============================] - 1s 653us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 34/150\n",
      "1400/1400 [==============================] - 1s 687us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 35/150\n",
      "1400/1400 [==============================] - 1s 651us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 36/150\n",
      "1400/1400 [==============================] - 1s 669us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 37/150\n",
      "1400/1400 [==============================] - 1s 674us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 38/150\n",
      "1400/1400 [==============================] - 1s 668us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 39/150\n",
      "1400/1400 [==============================] - 1s 671us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 40/150\n",
      "1400/1400 [==============================] - 1s 662us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 41/150\n",
      "1400/1400 [==============================] - 1s 660us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 42/150\n",
      "1400/1400 [==============================] - 1s 663us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 43/150\n",
      "1400/1400 [==============================] - 1s 673us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 44/150\n",
      "1400/1400 [==============================] - 1s 689us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 45/150\n",
      "1400/1400 [==============================] - 1s 676us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 46/150\n",
      "1400/1400 [==============================] - 1s 665us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 47/150\n",
      "1400/1400 [==============================] - 1s 661us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 48/150\n",
      "1400/1400 [==============================] - 1s 695us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 49/150\n",
      "1400/1400 [==============================] - 1s 665us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 50/150\n",
      "1400/1400 [==============================] - 1s 690us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 51/150\n",
      "1400/1400 [==============================] - 1s 683us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 52/150\n",
      "1400/1400 [==============================] - 1s 655us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 53/150\n",
      "1400/1400 [==============================] - 1s 652us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 54/150\n",
      "1400/1400 [==============================] - 1s 658us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 55/150\n",
      "1400/1400 [==============================] - 1s 738us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 56/150\n",
      "1400/1400 [==============================] - 1s 747us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 57/150\n",
      "1400/1400 [==============================] - 1s 684us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 58/150\n",
      "1400/1400 [==============================] - 1s 678us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 59/150\n",
      "1400/1400 [==============================] - 1s 682us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 60/150\n",
      "1400/1400 [==============================] - 1s 707us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 61/150\n",
      "1400/1400 [==============================] - 1s 709us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 62/150\n",
      "1400/1400 [==============================] - 1s 665us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 63/150\n",
      "1400/1400 [==============================] - 1s 668us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 64/150\n",
      "1400/1400 [==============================] - 1s 670us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 65/150\n",
      "1400/1400 [==============================] - 1s 676us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 66/150\n",
      "1400/1400 [==============================] - 1s 675us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 67/150\n",
      "1400/1400 [==============================] - 1s 665us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 68/150\n",
      "1400/1400 [==============================] - 1s 701us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 69/150\n",
      "1400/1400 [==============================] - 1s 698us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 70/150\n",
      "1400/1400 [==============================] - 1s 666us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 71/150\n",
      "1400/1400 [==============================] - 1s 669us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 72/150\n",
      "1400/1400 [==============================] - 1s 682us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 73/150\n",
      "1400/1400 [==============================] - 1s 693us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 74/150\n",
      "1400/1400 [==============================] - 1s 699us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 75/150\n",
      "1400/1400 [==============================] - 1s 677us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 76/150\n",
      "1400/1400 [==============================] - 1s 685us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 77/150\n",
      "1400/1400 [==============================] - 1s 696us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400/1400 [==============================] - 1s 682us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 79/150\n",
      "1400/1400 [==============================] - 1s 673us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 80/150\n",
      "1400/1400 [==============================] - 1s 669us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 81/150\n",
      "1400/1400 [==============================] - 1s 667us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 82/150\n",
      "1400/1400 [==============================] - 1s 681us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 83/150\n",
      "1400/1400 [==============================] - 1s 677us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 84/150\n",
      "1400/1400 [==============================] - 1s 673us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 85/150\n",
      "1400/1400 [==============================] - 1s 666us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 86/150\n",
      "1400/1400 [==============================] - 1s 664us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 87/150\n",
      "1400/1400 [==============================] - 1s 672us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 88/150\n",
      "1400/1400 [==============================] - 1s 668us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 89/150\n",
      "1400/1400 [==============================] - 1s 653us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 90/150\n",
      "1400/1400 [==============================] - 1s 663us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 91/150\n",
      "1400/1400 [==============================] - 1s 670us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 92/150\n",
      "1400/1400 [==============================] - 1s 683us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 93/150\n",
      "1400/1400 [==============================] - 1s 673us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 94/150\n",
      "1400/1400 [==============================] - 1s 664us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 95/150\n",
      "1400/1400 [==============================] - 1s 659us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 96/150\n",
      "1400/1400 [==============================] - 1s 669us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 97/150\n",
      "1400/1400 [==============================] - 1s 654us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 98/150\n",
      "1400/1400 [==============================] - 1s 683us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 99/150\n",
      "1400/1400 [==============================] - 1s 671us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 100/150\n",
      "1400/1400 [==============================] - 1s 669us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 101/150\n",
      "1400/1400 [==============================] - 1s 665us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 102/150\n",
      "1400/1400 [==============================] - 1s 668us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 103/150\n",
      "1400/1400 [==============================] - 1s 659us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 104/150\n",
      "1400/1400 [==============================] - 1s 695us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 105/150\n",
      "1400/1400 [==============================] - 1s 667us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 106/150\n",
      "1400/1400 [==============================] - 1s 675us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 107/150\n",
      "1400/1400 [==============================] - 1s 650us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 108/150\n",
      "1400/1400 [==============================] - 1s 763us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 109/150\n",
      "1400/1400 [==============================] - 1s 670us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 110/150\n",
      "1400/1400 [==============================] - 1s 665us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 111/150\n",
      "1400/1400 [==============================] - 1s 676us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 112/150\n",
      "1400/1400 [==============================] - 1s 652us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 113/150\n",
      "1400/1400 [==============================] - 1s 659us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 114/150\n",
      "1400/1400 [==============================] - 1s 670us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 115/150\n",
      "1400/1400 [==============================] - 1s 663us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 116/150\n",
      "1400/1400 [==============================] - 1s 670us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 117/150\n",
      "1400/1400 [==============================] - 1s 652us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 118/150\n",
      "1400/1400 [==============================] - 1s 669us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 119/150\n",
      "1400/1400 [==============================] - 1s 667us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 120/150\n",
      "1400/1400 [==============================] - 1s 670us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 121/150\n",
      "1400/1400 [==============================] - 1s 684us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 122/150\n",
      "1400/1400 [==============================] - 1s 665us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 123/150\n",
      "1400/1400 [==============================] - 1s 682us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 124/150\n",
      "1400/1400 [==============================] - 1s 675us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 125/150\n",
      "1400/1400 [==============================] - 1s 666us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 126/150\n",
      "1400/1400 [==============================] - 1s 707us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 127/150\n",
      "1400/1400 [==============================] - 1s 663us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 128/150\n",
      "1400/1400 [==============================] - 1s 669us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 129/150\n",
      "1400/1400 [==============================] - 1s 661us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 130/150\n",
      "1400/1400 [==============================] - 1s 668us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 131/150\n",
      "1400/1400 [==============================] - 1s 683us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 132/150\n",
      "1400/1400 [==============================] - 1s 680us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 133/150\n",
      "1400/1400 [==============================] - 1s 680us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 134/150\n",
      "1400/1400 [==============================] - 1s 673us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 135/150\n",
      "1400/1400 [==============================] - 1s 694us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 136/150\n",
      "1400/1400 [==============================] - 1s 697us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 137/150\n",
      "1400/1400 [==============================] - 1s 701us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 138/150\n",
      "1400/1400 [==============================] - 1s 683us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 139/150\n",
      "1400/1400 [==============================] - 1s 676us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 140/150\n",
      "1400/1400 [==============================] - 1s 676us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 141/150\n",
      "1400/1400 [==============================] - 1s 657us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 142/150\n",
      "1400/1400 [==============================] - 1s 704us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 143/150\n",
      "1400/1400 [==============================] - 1s 681us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 144/150\n",
      "1400/1400 [==============================] - 1s 695us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 145/150\n",
      "1400/1400 [==============================] - 1s 668us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 146/150\n",
      "1400/1400 [==============================] - 1s 683us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 147/150\n",
      "1400/1400 [==============================] - 1s 668us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 148/150\n",
      "1400/1400 [==============================] - 1s 667us/step - loss: 0.2009 - accuracy: 0.9492\n",
      "Epoch 149/150\n",
      "1400/1400 [==============================] - 1s 686us/step - loss: 0.2008 - accuracy: 0.9492\n",
      "Epoch 150/150\n",
      "1400/1400 [==============================] - 1s 675us/step - loss: 0.2009 - accuracy: 0.9492\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#classifier.fit(X_train, y_train, batch_size = 10, epochs= 100)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "#Dividir em conjunto de treino e conjunto de teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=18)\n",
    "\n",
    "#---------------------Cirar a Rede Neuronal Artificial--------------------------\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from numpy import loadtxt\n",
    "X_train=np.asarray(X_train).astype(np.int)\n",
    "\n",
    "y_train=np.asarray(y_train).astype(np.int)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Adicionar a Input Layer e a primeira hidden layers\n",
    "model.add(Dense(12, input_dim=4, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#Compiling the ANN\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#classifier.fit(X_train, y_train, batch_size = 10, epochs= 100)\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)\n",
    "\n",
    "accuracy = model.evaluate(X, y, verbose=0)\n",
    "print(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T21:55:57.341658Z",
     "iopub.status.busy": "2022-05-30T21:55:57.341193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ann_visualizer in c:\\users\\paulo garrido\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\paulo garrido\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "#Grafico da rede neuronal\n",
    "!pip3 install ann_visualizer\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T21:52:11.860752Z",
     "iopub.status.busy": "2022-05-30T21:52:11.859624Z",
     "iopub.status.idle": "2022-05-30T21:55:14.341386Z",
     "shell.execute_reply": "2022-05-30T21:55:14.339580Z",
     "shell.execute_reply.started": "2022-05-30T21:52:11.860710Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from ann_visualizer.visualize import ann_viz;\n",
    "ann_viz(model, title=\"VisualizaÃ§Ã£o da Rede Neuronal InsolvÃªncia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "Fraud, Probabilidade=0\n",
      "Requirement already satisfied: ann_visualizer in c:\\users\\paulo garrido\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\paulo garrido\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "#Carregar novo dado\n",
    "dataset = pd.read_csv('../Fraud/dataset/novocaso.csv',sep=',',header=0)\n",
    "X_new = dataset.drop('EVENT_LABEL', axis=1)   #Colunas usadas para calcular a Insolvencia. ContÃªm as features\n",
    "\n",
    "\n",
    "#Fazer a previsÃ£o de y - InsolvÃªncia\n",
    "predictions= np.argmax(model.predict(X_new),axis=1)\n",
    "\n",
    "\n",
    "if predictions[0] == 0:\n",
    "  print(\"Fraud, Probabilidade=%s\" % (predictions[0]))\n",
    "else:\n",
    "  print(\"Legit, Probabilidade=%s\" % (predictions[0]))\n",
    "\n",
    "#Grafico da rede neuronal\n",
    "!pip3 install ann_visualizer\n",
    "!pip install graphviz\n",
    "\n",
    "from ann_visualizer.visualize import ann_viz;\n",
    "ann_viz(model, title=\"VisualizaÃ§Ã£o da Rede Neuronal InsolvÃªncia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
